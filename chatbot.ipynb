{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers accelerate bitsandbytes gradio torch\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nimport torch\nimport gradio as gr\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:21:11.701941Z","iopub.execute_input":"2025-10-12T16:21:11.702253Z","iopub.status.idle":"2025-10-12T16:21:15.451216Z","shell.execute_reply.started":"2025-10-12T16:21:11.702233Z","shell.execute_reply":"2025-10-12T16:21:15.450295Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Model Tokenizer & pipeline","metadata":{}},{"cell_type":"code","source":"MODEL_ID = \"Qwen/Qwen3-4B-Instruct-2507\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID,\n    device_map=\"auto\",\n    torch_dtype=torch.float16,\n    load_in_4bit=True\n)\n\nchatbot = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:21:15.452931Z","iopub.execute_input":"2025-10-12T16:21:15.453199Z","iopub.status.idle":"2025-10-12T16:21:27.264231Z","shell.execute_reply.started":"2025-10-12T16:21:15.453176Z","shell.execute_reply":"2025-10-12T16:21:27.263522Z"}},"outputs":[{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"991e147bdb4c42208fbf8f4c24ba62b3"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# chat_response","metadata":{}},{"cell_type":"code","source":"def ask_bot(user_input, max_tokens=300):\n    \n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Answer with short, useful replies in the user's language.\"},\n        {\"role\": \"user\", \"content\": user_input}\n    ]\n\n    prompt = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n\n    outputs = chatbot(\n        prompt,\n        max_new_tokens=max_tokens,\n        temperature=0.6,\n        top_p=0.85,\n        do_sample=True\n    )\n\n    reply = outputs[0][\"generated_text\"][len(prompt):].strip()\n    return reply","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:21:27.266879Z","iopub.execute_input":"2025-10-12T16:21:27.267203Z","iopub.status.idle":"2025-10-12T16:21:27.272072Z","shell.execute_reply.started":"2025-10-12T16:21:27.267184Z","shell.execute_reply":"2025-10-12T16:21:27.271442Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Gradio Interface","metadata":{}},{"cell_type":"code","source":"with gr.Blocks(title=\" Chatbot (Zaki) \") as demo:\n    with gr.Row():\n        user_input = gr.Textbox(label=\" Write your question \")\n        output = gr.Textbox(label=\" answer \")\n    submit_btn = gr.Button(\"send\")\n    submit_btn.click(fn=ask_bot, inputs=user_input, outputs=output)\n\ndemo.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T16:21:27.273270Z","iopub.execute_input":"2025-10-12T16:21:27.273528Z","iopub.status.idle":"2025-10-12T16:21:28.624415Z","shell.execute_reply.started":"2025-10-12T16:21:27.273511Z","shell.execute_reply":"2025-10-12T16:21:28.623629Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7861\n* Running on public URL: https://b58dfad5dc62123079.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://b58dfad5dc62123079.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":11}]}